% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Bank Marketing Data Analysis - Project Report},
  pdfauthor={STAT 420, Summer 2020, Bhushan Bathani, Matthew Leung, Vijayakumar Sitha Mohan,},
  colorlinks=true,
  linkcolor=Maroon,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=cyan,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

\title{Bank Marketing Data Analysis - Project Report}
\author{STAT 420, Summer 2020, Bhushan Bathani, Matthew Leung, Vijayakumar Sitha
Mohan,}
\date{}

\begin{document}
\maketitle

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#install.packages("e1071")}
\KeywordTok{library}\NormalTok{(knitr)      }\CommentTok{# web widget}
\KeywordTok{library}\NormalTok{(tidyverse)  }\CommentTok{# data manipulation}
\KeywordTok{library}\NormalTok{(data.table) }\CommentTok{# fast file reading}
\KeywordTok{library}\NormalTok{(caret)      }\CommentTok{# rocr analysis}
\KeywordTok{library}\NormalTok{(ROCR)       }\CommentTok{# rocr analysis}
\KeywordTok{library}\NormalTok{(kableExtra) }\CommentTok{# nice table html formating }
\KeywordTok{library}\NormalTok{(gridExtra)  }\CommentTok{# arranging ggplot in grid}
\KeywordTok{library}\NormalTok{(rpart)      }\CommentTok{# decision tree}
\KeywordTok{library}\NormalTok{(rpart.plot) }\CommentTok{# decision tree plotting}
\KeywordTok{library}\NormalTok{(caTools)    }\CommentTok{# split}
\KeywordTok{library}\NormalTok{(lmtest)}
\KeywordTok{library}\NormalTok{(randomForest)}
\KeywordTok{library}\NormalTok{(ada)}
\KeywordTok{library}\NormalTok{(boot)}
\KeywordTok{library}\NormalTok{(e1071)      }\CommentTok{# caret depends on this}
\KeywordTok{library}\NormalTok{(ada)}
\KeywordTok{library}\NormalTok{(ROSE)}
\KeywordTok{library}\NormalTok{(DMwR)}
\KeywordTok{library}\NormalTok{(latticeExtra)}
\KeywordTok{library}\NormalTok{(pROC)}
\end{Highlighting}
\end{Shaded}

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

Our team selected a dataset of direct banking marketing of a Portuguese
bank. The goal is to predict if the client subscribe to the bank term
deposit. The dataset has client personal attributes, marketing campaign
attributes, social and economic context attributes. The response
variable (y) is binomial with value either 1 (subscribe) or 0 (not
subscribe).

Our team is interested in various classification technique performance.
We selected this dataset because it is a clean dataset for
classification. It has been top ten most popular from the data
repository that we download from. We can focus on analyzing
classification techniques rather then cleaning data. The URL to the
dataset is \url{http://archive.ics.uci.edu/ml/datasets/Bank+Marketing}.

We picked the following three classification techniques for this
project:

\begin{itemize}
\item
  Logistic Regression (It is covered in this course STAT420)
\item
  Random Forest (Very popular technique in Ensemble learning with a
  number of weak classifier based on decision tree)
\item
  Adaptive Boosting (More sophisticated technique in Ensemble learning
  with a number of weak classifier based on decision tree)
\end{itemize}

\hypertarget{methods}{%
\subsection{Methods}\label{methods}}

\hypertarget{understanding-data}{%
\subsubsection{Understanding Data}\label{understanding-data}}

\begin{itemize}
\item
  The Bank-Marketing dataset is downloaded from UCI Machine Learning
  Repository and the same is available at
  \url{http://archive.ics.uci.edu/ml/datasets/Bank+Marketing}.
\item
  There were 4 datasets in it from which bank-additional.csv is used
  that has subset of 4,119 observations out of all available
  observations of 41,188 in the full dataset.
\item
  20 inputs ordered by date (from May 2008 to November 2010). There are
  20 input variables and 1 output variable (desired target).
\item
  The dataset has customer data, socio-economic data, telemarketing data
  and some other data. Some attributes are numerical, and some are
  categorical.
\item
  There are 4 categories of data in the dataset.

  \begin{itemize}
  \item
    Customer's demographic information -
    age,job,marital,education,default,housing,loan
  \item
    Customer's financial data - default, hosing loan, personal loan
  \item
    Campaign and Marketing related data -
    contact,month,day\_of\_week,duration,campaign,pdays,previous,poutcome
  \item
    Overall market and economic indicators -
    emp.var.rate,cons.price.idx,cons.conf.idx,euribor3m,nr.employed
  \end{itemize}
\end{itemize}

\textbf{Attribute Information:}

\begin{table}[H]
\centering
\begin{tabular}{l|l|l}
\hline
Column.Name & Type & Description\\
\hline
age & Numeric & Client Age\\
\hline
job & Categorical & Type of Job\\
\hline
marital & Categorical & Client’s marital status\\
\hline
education & Categorical & Client’s education\\
\hline
default & Categorical & has credit in default?\\
\hline
housing & Categorical & has housing loan?\\
\hline
loan & Categorical & has personal loadn?\\
\hline
contact & string & contact communication type\\
\hline
day & Categorical & Day of last contact with client\\
\hline
month & Categorical & Month of last contact with client\\
\hline
duration & Numeric & last contact duration, in seconds\\
\hline
campaign & Numeric & number of contacts performed during this campaign and for this client\\
\hline
pdays & Numeric & number of days that passed by after the client was last contacted from a previous campaign\\
\hline
previous & Numeric & Number of client contacts performed before this campaign\\
\hline
poutcome & Categorical & outcome of the previous marketing campaign\\
\hline
emp.var.rate & Numeric & Quarterly employment variation rate\\
\hline
cons.price.idx & Numeric & Monthly consumer price index\\
\hline
cons.conf.idx & Numeric & Monthly consumer confidence index\\
\hline
euribor3m & Numeric & Daily euribor 3-month rate\\
\hline
nr.employed & Numeric & Quarterly number of employees\\
\hline
Term Deposit & Binary & has the client subscribed a term deposit\\
\hline
\end{tabular}
\end{table}

\begin{itemize}
\tightlist
\item
  Output variable (desired target) is \textbf{Term Deposit} which is
  categorical binary variable.
\end{itemize}

\hypertarget{data-validation}{%
\paragraph{Data Validation}\label{data-validation}}

\textbf{Checking for Missing value}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(bank_df1))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{itemize}
\tightlist
\item
  There are 0 rows with missing (NA) value in any of the columns.
\end{itemize}

\hypertarget{data-curation-cleaning-missing-data-duplicate}{%
\paragraph{Data Curation (cleaning , missing data,
duplicate)}\label{data-curation-cleaning-missing-data-duplicate}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{paste}\NormalTok{(}\StringTok{"There are "}\NormalTok{, }\KeywordTok{sum}\NormalTok{(}\KeywordTok{duplicated}\NormalTok{(bank_df1)), }\StringTok{"Duplicate Row(s)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "There are  2 Duplicate Row(s)"
\end{verbatim}

\textbf{Remove Duplicates}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_df =}\StringTok{ }\NormalTok{bank_df1 }\OperatorTok{%>%}\StringTok{ }\NormalTok{distinct}
\end{Highlighting}
\end{Shaded}

\textbf{Recode categorical attributes as factor variables}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{y =}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{y}\OperatorTok{==}\StringTok{'yes'}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{y =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{y)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{job =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{job)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{education =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{education)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{marital =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{marital)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{default =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{default)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{housing =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{housing)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{loan =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{loan)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{contact =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{contact)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{month =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{month)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{poutcome =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{poutcome)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{day_of_week =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{day_of_week)}
\NormalTok{bank_df}\OperatorTok{$}\NormalTok{default =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{default)}
\end{Highlighting}
\end{Shaded}

\textbf{Verify Levels of Categorical attributes}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{job)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "admin."        "blue-collar"   "entrepreneur"  "housemaid"    
##  [5] "management"    "retired"       "self-employed" "services"     
##  [9] "student"       "technician"    "unemployed"    "unknown"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{marital)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "divorced" "married"  "single"   "unknown"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{education)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "basic.4y"            "basic.6y"            "basic.9y"           
## [4] "high.school"         "illiterate"          "professional.course"
## [7] "university.degree"   "unknown"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{default)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "no"      "unknown" "yes"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{housing)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "no"      "unknown" "yes"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{loan)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "no"      "unknown" "yes"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{contact)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "cellular"  "telephone"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{month)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "apr" "aug" "dec" "jul" "jun" "mar" "may" "nov" "oct" "sep"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{poutcome)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "failure"     "nonexistent" "success"
\end{verbatim}

\hypertarget{data-analysis}{%
\paragraph{Data Analysis}\label{data-analysis}}

Let's see the levels and frequency of these data at higher level in
histogram to have a sense of data distributed.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{21}\NormalTok{)\{}
  \KeywordTok{barplot}\NormalTok{(}\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(bank_df[,i])) , }
          \DataTypeTok{xlab=}\KeywordTok{names}\NormalTok{(bank_df[i]), }\DataTypeTok{ylab=} \StringTok{"Frequency (%)"}\NormalTok{ , }\DataTypeTok{col =} \KeywordTok{rainbow}\NormalTok{(}\DecValTok{3}\NormalTok{), }\DataTypeTok{horiz =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-9-1.pdf}
\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-9-2.pdf}
\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-9-3.pdf}
\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-9-4.pdf}
\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-9-5.pdf}
\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-9-6.pdf}

\begin{itemize}
\item
  The above barplots show frequency distribution of each attribute in
  the dataset.
\item
  Let's analyze the dataset for any linearity between predictors and y
  using boxplot and pairs.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pairs}\NormalTok{(bank_df[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{,}\DecValTok{21}\NormalTok{)], }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{, }\DataTypeTok{gap =} \FloatTok{.25}\NormalTok{, }\DataTypeTok{xaxt =} \StringTok{"n"}\NormalTok{, }\DataTypeTok{yaxt =} \StringTok{"n"}
\NormalTok{      , }\DataTypeTok{col =} \KeywordTok{c}\NormalTok{(}\StringTok{"#0080FF"}\NormalTok{, }\StringTok{"#F3953E"}\NormalTok{)[bank_df}\OperatorTok{$}\NormalTok{y]}
\NormalTok{      , }\DataTypeTok{label.pos =} \FloatTok{.5}\NormalTok{, }\DataTypeTok{oma =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-11-1.pdf}

\begin{itemize}
\item
  pairs() function, which plots all possible scatterplots between pairs
  of variables in the dataset.
\item
  There are no obvious colinearity between predictors
  \texttt{age},\texttt{job},\texttt{education} and \texttt{marital}.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\CommentTok{#--- This is duplicate code. already we factorized this attributes.}

\NormalTok{bank_df}\OperatorTok{$}\NormalTok{jobclass =}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{job,}\DataTypeTok{levels=}\KeywordTok{c}\NormalTok{(}\StringTok{"unknown"}\NormalTok{,}\StringTok{"unemployed"}\NormalTok{,}\StringTok{"housemaid"}\NormalTok{, }\StringTok{"student"}\NormalTok{,}\StringTok{"retired"}\NormalTok{,}\StringTok{"technician"}\NormalTok{,}\StringTok{"blue-collar"}\NormalTok{,}\StringTok{"admin."}\NormalTok{,}\StringTok{"services"}\NormalTok{,}\StringTok{"self-employed"}\NormalTok{,}\StringTok{"management"}\NormalTok{,}\StringTok{"entrepreneur"}\NormalTok{),}\DataTypeTok{ordered=}\OtherTok{TRUE}\NormalTok{))}

\NormalTok{bank_df}\OperatorTok{$}\NormalTok{educationNum =}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{factor}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{education,}\DataTypeTok{levels=}\KeywordTok{c}\NormalTok{(}\StringTok{"unknown"}\NormalTok{,}\StringTok{"illiterate"}\NormalTok{,}\StringTok{"basic.4y"}\NormalTok{,}\StringTok{"basic.6y"}\NormalTok{,}\StringTok{"basic.9y"}\NormalTok{,}\StringTok{"high.school"}\NormalTok{,}\StringTok{"professional.course"}\NormalTok{, }\StringTok{"university.degree"}\NormalTok{),}\DataTypeTok{ordered=}\OtherTok{TRUE}\NormalTok{))}

\CommentTok{#---}

\KeywordTok{boxplot}\NormalTok{(age}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"age vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(jobclass}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"Job vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(marital)}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"Marital status vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(educationNum}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"Education vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-12-1.pdf}

Based on the above bar plots of individual predictors against
\texttt{Term\ Deposit},

\begin{itemize}
\item
  It is evident that the Customers in the age group between 30 and 50
  years subscribes to the term deposit than other age groups in the
  dataset.
\item
  Customers with an education higher than high school takes the loan and
  subscribes to the term deposit vs not.
\item
  Customers who are married subscribes to the term deposit more compared
  to others.
\item
  Customers with job title as technician, blue-color, admin and work in
  services sector subscribes to the term deposit than others.
\item
  So over all, It seems that age have some impact on term deposit
  subscription but need to see which exact range between 30-50 in
  detail. Rest parameters does not have any significant effect based on
  plot.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pairs}\NormalTok{(bank_df[}\KeywordTok{c}\NormalTok{(}\DecValTok{5}\OperatorTok{:}\DecValTok{7}\NormalTok{,}\DecValTok{21}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-13-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(default)}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"Default vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(housing)}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"Housing Loan vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(loan)}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"Personal loan vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-14-1.pdf}

\begin{itemize}
\tightlist
\item
  Customers with the housing loan and personal loan has no impact on
  term deposit subscription.
\item
  Customers already in default certainly did not subscribed to the term
  deposit. So default can be a very good predictor.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pairs}\NormalTok{(bank_df[}\KeywordTok{c}\NormalTok{(}\DecValTok{8}\OperatorTok{:}\DecValTok{15}\NormalTok{,}\DecValTok{21}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-15-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}

\KeywordTok{levels}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{contact)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "cellular"  "telephone"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(contact)}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"Contact Type vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(month)}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"last contact month of year vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(day_of_week)}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{" last contact day of the week vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(duration}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"last contact duration, in seconds vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-15-2.pdf}

\begin{itemize}
\tightlist
\item
  Based on plots, Customer with contact type cellular has more
  probability of subscribing for term deposit than telephone. People who
  was recently contacted has more chance of subscribing for term
  deposit. Last contact day of the week does not have much
  impact.Contact duraction has some impact on the term deposit
  subscription as well.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{boxplot}\NormalTok{(campaign}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"# of contacts in this campaign vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(pdays}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"number of days that passed by after the client was last contacted vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(previous}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"# of contacts performed before this campaign vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(poutcome)}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{" Previous Campain outcome vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-16-1.pdf}

\begin{itemize}
\tightlist
\item
  Based on above plot, \# of contact performed has some impact on Term
  deposit output else no other factor has significant
  impact.surprisingly \# of contacts in this campaign decreases the
  probability to subscribe for term deposit.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pairs}\NormalTok{(bank_df[}\KeywordTok{c}\NormalTok{(}\DecValTok{16}\OperatorTok{:}\DecValTok{20}\NormalTok{,}\DecValTok{21}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-17-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{boxplot}\NormalTok{(emp.var.rate}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"employment variation rate  vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(cons.price.idx}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"consumer price index vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(cons.conf.idx}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"consumer confidence index  vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(euribor3m}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"euribor 3 month rate  vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(nr.employed}\OperatorTok{~}\NormalTok{y,}\DataTypeTok{data=}\NormalTok{bank_df,}\DataTypeTok{main=}\StringTok{"number of employees vs Term Deposit"}\NormalTok{,}\DataTypeTok{pch=}\DecValTok{20}\NormalTok{,}\DataTypeTok{cex=}\DecValTok{2}\NormalTok{,}\DataTypeTok{col=}\StringTok{"darkorange"}\NormalTok{,}\DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-17-2.pdf}

\begin{itemize}
\tightlist
\item
  Based on plots all the market indicators has some impact on term
  deposit decision.
\end{itemize}

\hypertarget{class-imbalance-problem-analysis}{%
\paragraph{Class Imbalance Problem
analysis}\label{class-imbalance-problem-analysis}}

\begin{itemize}
\tightlist
\item
  We say that the dataset have the class imbalance problem, where the
  main class of interest is rare. That is, the data set distribution
  reflects a significant majority of the negative class and a minority
  positive class. Below table investigation shows that. we have
  \texttt{89} positive classes and \texttt{11\%} negative classes.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##         0         1 
## 0.8904242 0.1095758
\end{verbatim}

\begin{itemize}
\item
  we need to address this problem otherwise our model won't able to
  predict correctly. Most of the traditional classifiers assume dataset
  have balanced class distribution.
\item
  There are techniques available to overcome this class imbalance
  problem. Lets consider few of those techniques are:

  \begin{itemize}
  \item
    Oversampling: Re-sampling of data from positive class
  \item
    Under-sampling: Randomly eliminate tuples from negative class
  \item
    Threshold-moving: Move the decision threshold, so that the rare
    class tuples are easier to classify, and hence, less chance of
    costly false negative errors.
  \end{itemize}
\item
  We have used two library packages \texttt{DMwR} and \texttt{ROSE}
  which has \texttt{SMOTE} and \texttt{ROSE} functions

  \begin{itemize}
  \item
    SMOTE: The general idea of this method is to artificially generate
    new examples of the minority class using the nearest neighbors of
    these cases. Furthermore, the majority class examples are also
    under-sampled, leading to a more balanced dataset.
  \item
    ROSE: ROSE (Random Over-Sampling Examples) aids the task of binary
    classification in the presence of rare classes. It produces a
    synthetic, possibly balanced, sample of data simulated according to
    a smoothed-bootstrap approach.
  \end{itemize}
\end{itemize}

\hypertarget{traintest-data-split}{%
\paragraph{Train/Test data split}\label{traintest-data-split}}

\begin{itemize}
\tightlist
\item
  First split the dataset into train and test split using
  \texttt{createDataPartition} from \texttt{caret} package. The below r
  code splits the dataset with 70:30 ratio.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{split<-}\KeywordTok{createDataPartition}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{y,}\DataTypeTok{p=}\FloatTok{0.7}\NormalTok{,}\DataTypeTok{list =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{train<-bank_df[split,]}
\NormalTok{test<-bank_df[}\OperatorTok{-}\NormalTok{split,]}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Lets verify the class distribution in Training and Testing dataset. We
  see that our training and test dataset have same distribution of
  negative and positive classes.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(train}\OperatorTok{$}\NormalTok{y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##         0         1 
## 0.8902735 0.1097265
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(test}\OperatorTok{$}\NormalTok{y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##         0         1 
## 0.8907767 0.1092233
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Lets apply the class imbalances improvement techniques which we
  discussed above and verify the results.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{smote_train <-}\StringTok{ }\KeywordTok{SMOTE}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ train)                         }
\NormalTok{rose_train <-}\StringTok{ }\KeywordTok{ROSE}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ train)}\OperatorTok{$}\NormalTok{data                   }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(smote_train}\OperatorTok{$}\NormalTok{y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##         0         1 
## 0.5714286 0.4285714
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.table}\NormalTok{(}\KeywordTok{table}\NormalTok{(rose_train}\OperatorTok{$}\NormalTok{y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##         0         1 
## 0.5081343 0.4918657
\end{verbatim}

\hypertarget{model-builing}{%
\subsubsection{Model Builing}\label{model-builing}}

\begin{itemize}
\tightlist
\item
  In this study, we will be considering one regression model (Logistic
  Regression), one Ensemble model (Random Forest) and one Boosting model
  (Adaptive Boosting). We will be applying the techniques which we
  learnt in this course as well as others to better predict the chosen
  dataset.
\end{itemize}

\hypertarget{model-1-logistic-regression}{%
\subsubsection{Model 1: Logistic
Regression}\label{model-1-logistic-regression}}

\begin{itemize}
\tightlist
\item
  As We have seen in boxplot comparison, age, default, contact type,
  last contact time, duration, \# of contacts and all market indicators
  has some impact on terms deposit. Let's create a additive model using
  these parameters, full additive model and run AIC and BIC search to
  identify the model it comes up with.
\end{itemize}

\hypertarget{full-addivite-model}{%
\paragraph{Full addivite model}\label{full-addivite-model}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_lr =}\StringTok{ }\KeywordTok{glm}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ train, }\DataTypeTok{family =} \StringTok{"binomial"}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(bank_lr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = y ~ ., family = "binomial", data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.2121  -0.2715  -0.1590  -0.0964   3.0662  
## 
## Coefficients: (3 not defined because of singularities)
##                                Estimate Std. Error z value Pr(>|z|)    
## (Intercept)                  -7.817e+01  1.465e+02  -0.534  0.59351    
## age                           1.083e-02  9.822e-03   1.103  0.27010    
## jobblue-collar                5.343e-02  3.313e-01   0.161  0.87188    
## jobentrepreneur              -2.002e-01  5.908e-01  -0.339  0.73476    
## jobhousemaid                  4.020e-01  5.469e-01   0.735  0.46225    
## jobmanagement                -1.653e-01  3.477e-01  -0.475  0.63462    
## jobretired                   -1.558e-01  4.245e-01  -0.367  0.71356    
## jobself-employed             -6.894e-01  4.966e-01  -1.388  0.16507    
## jobservices                   3.682e-01  3.561e-01   1.034  0.30113    
## jobstudent                    3.245e-01  4.791e-01   0.677  0.49829    
## jobtechnician                 4.514e-01  2.762e-01   1.635  0.10214    
## jobunemployed                 2.714e-01  4.905e-01   0.553  0.58009    
## jobunknown                    1.293e+00  9.756e-01   1.326  0.18489    
## maritalmarried                1.445e-01  2.852e-01   0.507  0.61238    
## maritalsingle                 2.708e-01  3.267e-01   0.829  0.40709    
## maritalunknown                8.525e-01  1.212e+00   0.703  0.48182    
## educationbasic.6y             3.304e-01  5.139e-01   0.643  0.52018    
## educationbasic.9y             4.562e-01  3.976e-01   1.147  0.25132    
## educationhigh.school          4.623e-01  3.830e-01   1.207  0.22734    
## educationilliterate           3.338e-01  1.432e+00   0.233  0.81565    
## educationprofessional.course  5.005e-01  4.143e-01   1.208  0.22700    
## educationuniversity.degree    7.086e-01  3.902e-01   1.816  0.06936 .  
## educationunknown              2.059e-01  4.944e-01   0.416  0.67705    
## defaultunknown                1.374e-01  2.588e-01   0.531  0.59539    
## defaultyes                   -1.207e+01  5.246e+02  -0.023  0.98165    
## housingunknown               -1.715e-01  6.082e-01  -0.282  0.77795    
## housingyes                   -4.650e-02  1.702e-01  -0.273  0.78475    
## loanunknown                          NA         NA      NA       NA    
## loanyes                       1.936e-01  2.204e-01   0.878  0.37988    
## contacttelephone             -6.927e-01  3.223e-01  -2.149  0.03164 *  
## monthaug                      7.947e-01  5.079e-01   1.565  0.11767    
## monthdec                      4.836e-01  8.787e-01   0.550  0.58212    
## monthjul                      4.738e-01  4.433e-01   1.069  0.28511    
## monthjun                      1.114e+00  5.347e-01   2.084  0.03718 *  
## monthmar                      2.422e+00  6.595e-01   3.673  0.00024 ***
## monthmay                     -3.085e-01  3.754e-01  -0.822  0.41127    
## monthnov                      6.154e-02  5.233e-01   0.118  0.90639    
## monthoct                      6.532e-01  6.517e-01   1.002  0.31617    
## monthsep                      4.846e-01  7.314e-01   0.663  0.50757    
## day_of_weekmon                1.236e-01  2.575e-01   0.480  0.63103    
## day_of_weekthu               -3.396e-03  2.634e-01  -0.013  0.98971    
## day_of_weektue               -1.217e-01  2.679e-01  -0.454  0.64967    
## day_of_weekwed                3.026e-01  2.698e-01   1.121  0.26209    
## duration                      5.925e-03  3.475e-04  17.049  < 2e-16 ***
## campaign                     -7.801e-02  5.190e-02  -1.503  0.13277    
## pdays                        -4.572e-04  7.910e-04  -0.578  0.56325    
## previous                      2.433e-01  2.308e-01   1.054  0.29192    
## poutcomenonexistent           9.367e-01  3.812e-01   2.457  0.01400 *  
## poutcomesuccess               1.605e+00  7.606e-01   2.111  0.03480 *  
## emp.var.rate                 -3.787e-01  5.543e-01  -0.683  0.49451    
## cons.price.idx                7.581e-01  9.647e-01   0.786  0.43194    
## cons.conf.idx                 5.912e-02  3.243e-02   1.823  0.06832 .  
## euribor3m                    -5.177e-01  5.140e-01  -1.007  0.31391    
## nr.employed                   9.732e-04  1.191e-02   0.082  0.93488    
## jobclass                             NA         NA      NA       NA    
## educationNum                         NA         NA      NA       NA    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1998.9  on 2888  degrees of freedom
## Residual deviance: 1075.6  on 2836  degrees of freedom
## AIC: 1181.6
## 
## Number of Fisher Scoring iterations: 14
\end{verbatim}

\hypertarget{model-based-on-data-analysis-from-boxplot}{%
\paragraph{Model based on data analysis from
boxplot}\label{model-based-on-data-analysis-from-boxplot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_lr_plotobs =}\StringTok{ }\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{age}\OperatorTok{+}\NormalTok{job}\OperatorTok{+}\NormalTok{default}\OperatorTok{+}\NormalTok{campaign}\OperatorTok{+}\NormalTok{previous}\OperatorTok{+}\NormalTok{contact }\OperatorTok{+}\StringTok{ }\NormalTok{month}\OperatorTok{+}\NormalTok{duration}\OperatorTok{+}\StringTok{ }\NormalTok{pdays}\OperatorTok{+}\NormalTok{emp.var.rate}\OperatorTok{+}\NormalTok{cons.price.idx}\OperatorTok{+}\NormalTok{cons.conf.idx}\OperatorTok{+}\NormalTok{euribor3m}\OperatorTok{+}\NormalTok{nr.employed, }\DataTypeTok{data =}\NormalTok{ train,}
                      \DataTypeTok{family =} \StringTok{"binomial"}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(bank_lr_plotobs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = y ~ age + job + default + campaign + previous + 
##     contact + month + duration + pdays + emp.var.rate + cons.price.idx + 
##     cons.conf.idx + euribor3m + nr.employed, family = "binomial", 
##     data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.2516  -0.2765  -0.1649  -0.1039   3.0507  
## 
## Coefficients:
##                    Estimate Std. Error z value Pr(>|z|)    
## (Intercept)      -8.065e+01  1.395e+02  -0.578   0.5632    
## age               4.007e-03  8.576e-03   0.467   0.6403    
## jobblue-collar   -1.756e-01  2.666e-01  -0.659   0.5101    
## jobentrepreneur  -2.935e-01  5.828e-01  -0.504   0.6145    
## jobhousemaid      2.142e-01  5.174e-01   0.414   0.6789    
## jobmanagement    -1.689e-01  3.387e-01  -0.499   0.6179    
## jobretired       -2.660e-01  4.119e-01  -0.646   0.5183    
## jobself-employed -7.066e-01  4.831e-01  -1.463   0.1436    
## jobservices       2.367e-01  3.231e-01   0.733   0.4638    
## jobstudent        6.276e-03  4.415e-01   0.014   0.9887    
## jobtechnician     3.493e-01  2.476e-01   1.411   0.1583    
## jobunemployed     1.798e-01  4.756e-01   0.378   0.7055    
## jobunknown        1.082e+00  9.245e-01   1.170   0.2419    
## defaultunknown    2.095e-02  2.515e-01   0.083   0.9336    
## defaultyes       -1.212e+01  5.311e+02  -0.023   0.9818    
## campaign         -8.066e-02  5.130e-02  -1.572   0.1159    
## previous         -2.057e-01  1.447e-01  -1.421   0.1552    
## contacttelephone -7.114e-01  3.204e-01  -2.221   0.0264 *  
## monthaug          8.747e-01  4.940e-01   1.770   0.0767 .  
## monthdec          5.666e-01  8.711e-01   0.650   0.5154    
## monthjul          4.844e-01  4.360e-01   1.111   0.2666    
## monthjun          1.142e+00  5.093e-01   2.242   0.0249 *  
## monthmar          2.526e+00  6.433e-01   3.927 8.59e-05 ***
## monthmay         -2.648e-01  3.635e-01  -0.728   0.4663    
## monthnov          9.647e-02  5.123e-01   0.188   0.8506    
## monthoct          6.175e-01  6.332e-01   0.975   0.3294    
## monthsep          3.568e-01  7.070e-01   0.505   0.6137    
## duration          5.845e-03  3.420e-04  17.094  < 2e-16 ***
## pdays            -1.798e-03  3.527e-04  -5.099 3.41e-07 ***
## emp.var.rate     -4.487e-01  5.311e-01  -0.845   0.3983    
## cons.price.idx    8.509e-01  9.168e-01   0.928   0.3533    
## cons.conf.idx     6.003e-02  3.134e-02   1.915   0.0554 .  
## euribor3m        -4.203e-01  5.007e-01  -0.839   0.4013    
## nr.employed       3.656e-04  1.140e-02   0.032   0.9744    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1998.9  on 2888  degrees of freedom
## Residual deviance: 1093.4  on 2855  degrees of freedom
## AIC: 1161.4
## 
## Number of Fisher Scoring iterations: 14
\end{verbatim}

\hypertarget{attribute-selection}{%
\paragraph{Attribute selection}\label{attribute-selection}}

We will be using step function to search forward and backward directions
and use AIC and BIC as metric to find out the best model.

\hypertarget{model-using-aic-search}{%
\paragraph{Model using AIC Search}\label{model-using-aic-search}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_lr_aic =}\StringTok{ }\KeywordTok{step}\NormalTok{(bank_lr, }\DataTypeTok{direction =} \StringTok{"backward"}\NormalTok{, }\DataTypeTok{trace =} \DecValTok{0}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(bank_lr_aic)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = y ~ contact + month + duration + campaign + previous + 
##     poutcome + cons.price.idx + cons.conf.idx + euribor3m, family = "binomial", 
##     data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.1263  -0.2769  -0.1641  -0.1023   3.2010  
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(>|z|)    
## (Intercept)         -4.032e+01  1.595e+01  -2.528 0.011457 *  
## contacttelephone    -6.154e-01  2.945e-01  -2.089 0.036688 *  
## monthaug             7.500e-01  4.315e-01   1.738 0.082207 .  
## monthdec             5.892e-01  8.195e-01   0.719 0.472097    
## monthjul             5.263e-01  4.217e-01   1.248 0.212075    
## monthjun             1.298e+00  3.840e-01   3.381 0.000722 ***
## monthmar             2.238e+00  5.642e-01   3.967 7.28e-05 ***
## monthmay            -4.121e-01  3.359e-01  -1.227 0.219852    
## monthnov             2.393e-01  4.223e-01   0.567 0.570921    
## monthoct             6.961e-01  5.117e-01   1.360 0.173730    
## monthsep             4.000e-01  5.298e-01   0.755 0.450193    
## duration             5.781e-03  3.373e-04  17.141  < 2e-16 ***
## campaign            -8.119e-02  5.118e-02  -1.586 0.112709    
## previous             3.048e-01  1.980e-01   1.539 0.123710    
## poutcomenonexistent  9.567e-01  3.650e-01   2.621 0.008759 ** 
## poutcomesuccess      1.943e+00  3.386e-01   5.739 9.53e-09 ***
## cons.price.idx       4.275e-01  1.768e-01   2.418 0.015615 *  
## cons.conf.idx        6.452e-02  2.157e-02   2.991 0.002783 ** 
## euribor3m           -7.521e-01  6.943e-02 -10.832  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1998.9  on 2888  degrees of freedom
## Residual deviance: 1096.4  on 2870  degrees of freedom
## AIC: 1134.4
## 
## Number of Fisher Scoring iterations: 7
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The \emph{best model based on AIC} include \texttt{contact},
  \texttt{month}, \texttt{duration}, \texttt{campaign},
  \texttt{poutcome}, \texttt{emp.var.rate}, \texttt{cons.price.idx},
  \texttt{cons.conf.idx}
\end{itemize}

\hypertarget{model-using-bic-search}{%
\paragraph{Model using BIC search}\label{model-using-bic-search}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n=}\KeywordTok{length}\NormalTok{(}\KeywordTok{resid}\NormalTok{(bank_lr))}
\NormalTok{bank_lr_bic =}\StringTok{ }\KeywordTok{step}\NormalTok{(bank_lr, }\DataTypeTok{direction =} \StringTok{"backward"}\NormalTok{, }\DataTypeTok{trace =} \DecValTok{0}\NormalTok{,}\DataTypeTok{k=}\KeywordTok{log}\NormalTok{(n))}
\NormalTok{bank_lr_bic}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:  glm(formula = y ~ contact + duration + poutcome + emp.var.rate + 
##     cons.price.idx + cons.conf.idx, family = "binomial", data = train)
## 
## Coefficients:
##         (Intercept)     contacttelephone             duration  
##          -1.390e+02           -1.107e+00            5.426e-03  
## poutcomenonexistent      poutcomesuccess         emp.var.rate  
##           6.340e-01            2.022e+00           -9.943e-01  
##      cons.price.idx        cons.conf.idx  
##           1.473e+00            8.726e-02  
## 
## Degrees of Freedom: 2888 Total (i.e. Null);  2881 Residual
## Null Deviance:       1999 
## Residual Deviance: 1151  AIC: 1167
\end{verbatim}

\begin{itemize}
\item
  The \emph{best model based on BIC} include \texttt{contact},
  \texttt{duration}, \texttt{poutcome}, \texttt{emp.var.rate},
  \texttt{cons.price.idx}, \texttt{cons.conf.idx}
\item
  The BIC model have lesser number of parameters compared to best AIC
  model. Let's do the Anova LRT test to find the preferred model.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
        \DataTypeTok{NullHypoThesis =} \KeywordTok{c}\NormalTok{(}\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{anova}\NormalTok{(bank_lr_bic,bank_lr,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]}\OperatorTok{<}\FloatTok{0.05}\NormalTok{,}\StringTok{"Rejected"}\NormalTok{,}\StringTok{"Fail To Reject"}\NormalTok{),}
           \KeywordTok{ifelse}\NormalTok{(}\KeywordTok{anova}\NormalTok{(bank_lr_aic,bank_lr,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]}\OperatorTok{<}\FloatTok{0.05}\NormalTok{,}\StringTok{"Rejected"}\NormalTok{,}\StringTok{"Fail To Reject"}\NormalTok{),}
           \KeywordTok{ifelse}\NormalTok{(}\KeywordTok{anova}\NormalTok{(bank_lr_bic,bank_lr_aic,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]}\OperatorTok{<}\FloatTok{0.05}\NormalTok{,}\StringTok{"Rejected"}\NormalTok{,}\StringTok{"Fail To Reject"}\NormalTok{),}
           \KeywordTok{ifelse}\NormalTok{(}\KeywordTok{anova}\NormalTok{(bank_lr_plotobs,bank_lr,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]}\OperatorTok{<}\FloatTok{0.05}\NormalTok{,}\StringTok{"Rejected"}\NormalTok{,}\StringTok{"Fail To Reject"}\NormalTok{),}
           \KeywordTok{ifelse}\NormalTok{(}\KeywordTok{anova}\NormalTok{(bank_lr_aic,bank_lr_plotobs,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]}\OperatorTok{<}\FloatTok{0.05}\NormalTok{,}\StringTok{"Rejected"}\NormalTok{,}\StringTok{"Fail To Reject"}\NormalTok{)),}
          \DataTypeTok{PValue =} \KeywordTok{c}\NormalTok{((}\KeywordTok{anova}\NormalTok{(bank_lr_bic,bank_lr,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]),}
\NormalTok{           (}\KeywordTok{anova}\NormalTok{(bank_lr_aic,bank_lr,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]),}
\NormalTok{           (}\KeywordTok{anova}\NormalTok{(bank_lr_bic,bank_lr_aic,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]),}
           \KeywordTok{anova}\NormalTok{(bank_lr_plotobs,bank_lr,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{],}
           \KeywordTok{anova}\NormalTok{(bank_lr_aic,bank_lr_plotobs,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)[}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{]),}
\DataTypeTok{row.names =} \KeywordTok{c}\NormalTok{(}\StringTok{"BIC vs Additive"}\NormalTok{,}\StringTok{"AIC vs Additive "}\NormalTok{,}\StringTok{"BIC vs AIC"}\NormalTok{,}\StringTok{"PlotObs vs Full Additive"}\NormalTok{,}\StringTok{"AIC vs PlotObs"}\NormalTok{)}
\NormalTok{)}

\KeywordTok{colnames}\NormalTok{(result) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Null Hypothesis"}\NormalTok{,}\StringTok{"P-Value"}\NormalTok{)}

\KeywordTok{kable}\NormalTok{(result) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{bootstrap_options =} \KeywordTok{c}\NormalTok{(}\StringTok{"striped"}\NormalTok{, }\StringTok{"hover"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}{l|l|r}
\hline
  & Null Hypothesis & P-Value\\
\hline
BIC vs Additive & Rejected & 0.0027841\\
\hline
AIC vs Additive & Fail To Reject & 0.9627218\\
\hline
BIC vs AIC & Rejected & 0.0000001\\
\hline
PlotObs vs Full Additive & Fail To Reject & 0.5370009\\
\hline
AIC vs PlotObs & Fail To Reject & 0.9995529\\
\hline
\end{tabular}
\end{table}

\begin{itemize}
\item
  Based on Anova LRT test above, only AIC model is the preferable model
  among all model.
\item
  Let's compare Null deviance, Residual Deviance, AIC and 5 fold
  misclassification rate to see which is the better model.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#train = na.omit(train)}
\CommentTok{#train = train[complete.cases(train), ]}
\CommentTok{#train = train[,-5]}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1983}\NormalTok{)}
\NormalTok{mcRate_bank_lr =}\StringTok{ }\KeywordTok{cv.glm}\NormalTok{(train,bank_lr,}\DataTypeTok{K=}\DecValTok{5}\NormalTok{)}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{] }\CommentTok{# TO DO: change model}
\NormalTok{mcRate_bank_lr_aic =}\StringTok{ }\KeywordTok{cv.glm}\NormalTok{(train,bank_lr_aic,}\DataTypeTok{K=}\DecValTok{5}\NormalTok{)}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{]}
\NormalTok{mcRate_bank_lr_bic =}\StringTok{ }\KeywordTok{cv.glm}\NormalTok{(train,bank_lr_bic,}\DataTypeTok{K=}\DecValTok{5}\NormalTok{)}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{]}
\NormalTok{mcRate_bank_lr_plotobs =}\StringTok{ }\KeywordTok{cv.glm}\NormalTok{(train,bank_lr_plotobs,}\DataTypeTok{K=}\DecValTok{5}\NormalTok{)}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{]}\CommentTok{#TO DO: Change Model}



\NormalTok{result =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{Residual_Deviance=}\KeywordTok{c}\NormalTok{(bank_lr}\OperatorTok{$}\NormalTok{deviance,bank_lr_aic}\OperatorTok{$}\NormalTok{deviance,bank_lr_bic}\OperatorTok{$}\NormalTok{deviance,bank_lr_plotobs}\OperatorTok{$}\NormalTok{deviance),}
  \DataTypeTok{Residual_DF=}\KeywordTok{c}\NormalTok{(bank_lr}\OperatorTok{$}\NormalTok{df.residual,bank_lr_aic}\OperatorTok{$}\NormalTok{df.residual,bank_lr_bic}\OperatorTok{$}\NormalTok{df.residual,bank_lr_plotobs}\OperatorTok{$}\NormalTok{df.residual),}
  \DataTypeTok{Null_Deviance=}\KeywordTok{c}\NormalTok{(bank_lr}\OperatorTok{$}\NormalTok{null.deviance,bank_lr_aic}\OperatorTok{$}\NormalTok{null.deviance,bank_lr_bic}\OperatorTok{$}\NormalTok{null.deviance,bank_lr_plotobs}\OperatorTok{$}\NormalTok{null.deviance),}
  \DataTypeTok{Null_DF=}\KeywordTok{c}\NormalTok{(bank_lr}\OperatorTok{$}\NormalTok{df.null,bank_lr_aic}\OperatorTok{$}\NormalTok{df.null,bank_lr_bic}\OperatorTok{$}\NormalTok{df.null,bank_lr_plotobs}\OperatorTok{$}\NormalTok{df.null),}
  \DataTypeTok{AIC=}\KeywordTok{c}\NormalTok{(}\KeywordTok{AIC}\NormalTok{(bank_lr),}\KeywordTok{AIC}\NormalTok{(bank_lr_aic),}\KeywordTok{AIC}\NormalTok{(bank_lr_bic),}\KeywordTok{AIC}\NormalTok{(bank_lr_plotobs)),}
  \DataTypeTok{MisclassificationRate=}\KeywordTok{c}\NormalTok{(mcRate_bank_lr,mcRate_bank_lr_aic,mcRate_bank_lr_bic,mcRate_bank_lr_plotobs),}
  \DataTypeTok{row.names =} \KeywordTok{c}\NormalTok{(}\StringTok{"Full Model"}\NormalTok{,}\StringTok{"Model Selected with AIC"}\NormalTok{,}\StringTok{"Model Selected with BIC"}\NormalTok{,}\StringTok{"Model built based on boxplot observation"}\NormalTok{)}
\NormalTok{)}

\KeywordTok{colnames}\NormalTok{(result) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Residual Deviance"}\NormalTok{,}\StringTok{"Residual DF"}\NormalTok{,}\StringTok{"Null Deviance"}\NormalTok{,}\StringTok{"Null DF"}\NormalTok{,}\StringTok{"AIC "}\NormalTok{,}\StringTok{"Misclassification Rate"}\NormalTok{)}

\KeywordTok{kable}\NormalTok{(result) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{bootstrap_options =} \KeywordTok{c}\NormalTok{(}\StringTok{"striped"}\NormalTok{, }\StringTok{"hover"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}{l|r|r|r|r|r|r}
\hline
  & Residual Deviance & Residual DF & Null Deviance & Null DF & AIC  & Misclassification Rate\\
\hline
Full Model & 1075.575 & 2836 & 1998.86 & 2888 & 1181.575 & 0.0636331\\
\hline
Model Selected with AIC & 1096.410 & 2870 & 1998.86 & 2888 & 1134.410 & 0.0580224\\
\hline
Model Selected with BIC & 1151.332 & 2881 & 1998.86 & 2888 & 1167.332 & 0.0597281\\
\hline
Model built based on boxplot observation & 1093.358 & 2855 & 1998.86 & 2888 & 1161.358 & 0.0609657\\
\hline
\end{tabular}
\end{table}

\begin{itemize}
\tightlist
\item
  Based on the table above, AIC model has the lowest Residual Deviance
  after Full model but degree of freedom is more closer to Null Deviance
  degree of freedom than Full Model. AIC of the AIC model and
  misclassification rate is also least.
\end{itemize}

Can we improve it further by applying the transformation or interaction
on AIC model? Let's check.

\hypertarget{apply-two-way-interaction}{%
\subparagraph{Apply two way
interaction}\label{apply-two-way-interaction}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_lr_aic_int =}\StringTok{ }\KeywordTok{glm}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{(contact }\OperatorTok{+}\StringTok{ }\NormalTok{month }\OperatorTok{+}\StringTok{ }\NormalTok{duration }\OperatorTok{+}\StringTok{ }\NormalTok{campaign }\OperatorTok{+}\StringTok{ }\NormalTok{poutcome }\OperatorTok{+}\StringTok{ }\NormalTok{cons.conf.idx }\OperatorTok{+}\StringTok{ }\NormalTok{nr.employed}\OperatorTok{+}\NormalTok{contact}\OperatorTok{:}\NormalTok{month}\OperatorTok{+}\NormalTok{campaign}\OperatorTok{:}\NormalTok{poutcome), }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link=}\StringTok{"logit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ train)}
\end{Highlighting}
\end{Shaded}

\hypertarget{apply-log-transformation-on-one-of-the-predictor}{%
\subparagraph{Apply Log Transformation on one of the
predictor}\label{apply-log-transformation-on-one-of-the-predictor}}

\begin{itemize}
\tightlist
\item
  We have chosen the predictor \texttt{nr.employed} since it is
  numerical attribute varying from small to large numbers.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{range}\NormalTok{(bank_df}\OperatorTok{$}\NormalTok{nr.employed)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4963.6 5228.1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_lr_aic_transform =}\StringTok{ }\KeywordTok{glm}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{(contact }\OperatorTok{+}\StringTok{ }\NormalTok{month }\OperatorTok{+}\StringTok{ }\NormalTok{duration }\OperatorTok{+}\StringTok{ }\NormalTok{campaign }\OperatorTok{+}\StringTok{ }\NormalTok{poutcome }\OperatorTok{+}\StringTok{ }\NormalTok{cons.conf.idx }\OperatorTok{+}\StringTok{ }\KeywordTok{log}\NormalTok{(nr.employed)), }
    \DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link=}\StringTok{"logit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ train)}
\end{Highlighting}
\end{Shaded}

\textbf{Use Anova LRT test to compare the aic additive model vs aic
interaction model}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{anova}\NormalTok{(bank_lr_aic,bank_lr_aic_int,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: y ~ contact + month + duration + campaign + previous + poutcome + 
##     cons.price.idx + cons.conf.idx + euribor3m
## Model 2: y ~ (contact + month + duration + campaign + poutcome + cons.conf.idx + 
##     nr.employed + contact:month + campaign:poutcome)
##   Resid. Df Resid. Dev Df Deviance Pr(>Chi)
## 1      2870     1096.4                     
## 2      2861     1092.5  9   3.8989   0.9179
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Since p-value is very large so we fail to reject the null hypothesis
  and we stick with our AIC additive model
\end{itemize}

\textbf{Use Anova LRT test to compare the aic additive model vs aic log
model}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{anova}\NormalTok{(bank_lr_aic,bank_lr_aic_transform,}\DataTypeTok{test=}\StringTok{"LRT"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: y ~ contact + month + duration + campaign + previous + poutcome + 
##     cons.price.idx + cons.conf.idx + euribor3m
## Model 2: y ~ (contact + month + duration + campaign + poutcome + cons.conf.idx + 
##     log(nr.employed))
##   Resid. Df Resid. Dev Df Deviance Pr(>Chi)  
## 1      2870     1096.4                       
## 2      2872     1101.9 -2   -5.469  0.06493 .
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{itemize}
\tightlist
\item
  At significant level \texttt{0.01}, so we fail to reject the null
  hypothesis and we stick with our AIC additive model
\end{itemize}

\textbf{Let's do 5 fold cross validation and calculate misclassification
rate to compare and select the model}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1250}\NormalTok{)}

\NormalTok{mcRate_bank_lr_aic_int =}\StringTok{ }\KeywordTok{cv.glm}\NormalTok{(train,bank_lr_aic_int,}\DataTypeTok{K=}\DecValTok{5}\NormalTok{)}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{] }\CommentTok{#  TO DO change model}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mcRate_bank_lr_aic_transform =}\StringTok{ }\KeywordTok{cv.glm}\NormalTok{(train,bank_lr_aic_transform,}\DataTypeTok{K=}\DecValTok{5}\NormalTok{)}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{] }\CommentTok{# TO DO Change model}

\NormalTok{result =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{Residual_Deviance=}\KeywordTok{c}\NormalTok{(bank_lr}\OperatorTok{$}\NormalTok{deviance,bank_lr_aic}\OperatorTok{$}\NormalTok{deviance,bank_lr_bic}\OperatorTok{$}\NormalTok{deviance,bank_lr_plotobs}\OperatorTok{$}\NormalTok{deviance,bank_lr_aic_int}\OperatorTok{$}\NormalTok{deviance,bank_lr_aic_transform}\OperatorTok{$}\NormalTok{deviance),}
  \DataTypeTok{Residual_DF=}\KeywordTok{c}\NormalTok{(bank_lr}\OperatorTok{$}\NormalTok{df.residual,bank_lr_aic}\OperatorTok{$}\NormalTok{df.residual,bank_lr_bic}\OperatorTok{$}\NormalTok{df.residual,bank_lr_plotobs}\OperatorTok{$}\NormalTok{df.residual,bank_lr_aic_int}\OperatorTok{$}\NormalTok{df.residual,bank_lr_aic_transform}\OperatorTok{$}\NormalTok{df.residual),}
  \DataTypeTok{Null_Deviance=}\KeywordTok{c}\NormalTok{(bank_lr}\OperatorTok{$}\NormalTok{null.deviance,bank_lr_aic}\OperatorTok{$}\NormalTok{null.deviance,bank_lr_bic}\OperatorTok{$}\NormalTok{null.deviance,bank_lr_plotobs}\OperatorTok{$}\NormalTok{null.deviance,bank_lr_aic_int}\OperatorTok{$}\NormalTok{null.deviance,bank_lr_aic_transform}\OperatorTok{$}\NormalTok{null.deviance),}
  \DataTypeTok{Null_DF=}\KeywordTok{c}\NormalTok{(bank_lr}\OperatorTok{$}\NormalTok{df.null,bank_lr_aic}\OperatorTok{$}\NormalTok{df.null,bank_lr_bic}\OperatorTok{$}\NormalTok{df.null,bank_lr_plotobs}\OperatorTok{$}\NormalTok{df.null,bank_lr_aic_int}\OperatorTok{$}\NormalTok{df.null,bank_lr_aic_transform}\OperatorTok{$}\NormalTok{df.null),}
  \DataTypeTok{AIC=}\KeywordTok{c}\NormalTok{(}\KeywordTok{AIC}\NormalTok{(bank_lr),}\KeywordTok{AIC}\NormalTok{(bank_lr_aic),}\KeywordTok{AIC}\NormalTok{(bank_lr_bic),}\KeywordTok{AIC}\NormalTok{(bank_lr_plotobs),}\KeywordTok{AIC}\NormalTok{(bank_lr_aic_int),}\KeywordTok{AIC}\NormalTok{(bank_lr_aic_transform)),}
  \DataTypeTok{MisclassificationRate=}\KeywordTok{c}\NormalTok{(mcRate_bank_lr,mcRate_bank_lr_aic,mcRate_bank_lr_bic,mcRate_bank_lr_plotobs,mcRate_bank_lr_aic_int,mcRate_bank_lr_aic_transform),}
  \DataTypeTok{row.names =} \KeywordTok{c}\NormalTok{(}\StringTok{"Full Model"}\NormalTok{,}\StringTok{"Model Selected with AIC"}\NormalTok{,}\StringTok{"Model Selected with BIC"}\NormalTok{,}\StringTok{"Model built based on boxplot observation"}\NormalTok{,}\StringTok{"Model with an interaction"}\NormalTok{,}\StringTok{"Model with transformation"}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(result,}\DataTypeTok{format=}\StringTok{"markdown"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
\begin{minipage}[b]{0.27\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedleft
Residual\_Deviance\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedleft
Residual\_DF\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedleft
Null\_Deviance\strut
\end{minipage} & \begin{minipage}[b]{0.05\columnwidth}\raggedleft
Null\_DF\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\raggedleft
AIC\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedleft
MisclassificationRate\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.27\columnwidth}\raggedright
Full Model\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
1075.575\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2836\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedleft
1998.86\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
2888\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
1181.575\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.0636331\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
Model Selected with AIC\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
1096.410\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2870\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedleft
1998.86\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
2888\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
1134.410\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.0580224\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
Model Selected with BIC\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
1151.332\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2881\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedleft
1998.86\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
2888\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
1167.332\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.0597281\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
Model built based on boxplot observation\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
1093.358\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2855\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedleft
1998.86\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
2888\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
1161.358\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.0609657\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
Model with an interaction\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
1092.511\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2861\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedleft
1998.86\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
2888\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
1148.511\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.0590018\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.27\columnwidth}\raggedright
Model with transformation\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
1101.879\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2872\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedleft
1998.86\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
2888\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
1135.879\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.0580032\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\item
  As you see, Residual deviance goes down with integration but AIC goes
  up and degrees of freedom goes down.Misclassification rate is
  marginally up with interaction. With transformation,we see marginally
  better results with Residual , AIC and misclassification rate.
\item
  Let's consider transformation model on test data to identify
  misclassification rate, false positives and negatives on Test data.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict_bank_lr_aic_transform =}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(}\KeywordTok{predict}\NormalTok{(bank_lr_aic_transform, test, }\DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}\OperatorTok{>}\StringTok{ }\FloatTok{0.5}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\NormalTok{misClassificationRate =}\StringTok{ }\KeywordTok{mean}\NormalTok{(predict_bank_lr_aic_transform}\OperatorTok{!=}\NormalTok{test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{misClassificationRate}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0881877
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{make_conf_mat =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(predicted, actual) \{}
  \KeywordTok{table}\NormalTok{(}\DataTypeTok{predicted =}\NormalTok{ predicted, }\DataTypeTok{actual =}\NormalTok{ actual)}
\NormalTok{\}}

\NormalTok{confusion_matrix =}\StringTok{ }\KeywordTok{table}\NormalTok{(}\DataTypeTok{predicted =}\NormalTok{ predict_bank_lr_aic_transform, }\DataTypeTok{actual =}\NormalTok{ test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{sensitivity =}\StringTok{ }\NormalTok{confusion_matrix[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]}\OperatorTok{/}\NormalTok{confusion_matrix[,}\DecValTok{2}\NormalTok{]}
\NormalTok{specificity =}\StringTok{ }\NormalTok{confusion_matrix[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{]}\OperatorTok{/}\NormalTok{confusion_matrix[,}\DecValTok{1}\NormalTok{]}

\NormalTok{confusion_matrix}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          actual
## predicted    0    1
##         0 1059   67
##         1   42   68
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sensitivity}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        0        1 
## 1.014925 1.000000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{specificity}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        0        1 
##  1.00000 25.21429
\end{verbatim}

\begin{itemize}
\tightlist
\item
  With cutoff of 0.5 probability , we see 42 false positives and 67
  false negatives among 1236 observations which is less than 10\%. We
  can try to identify cut off where this number goes down. Let's draw
  ROC curve and identify AUC.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{get_logistic_pred =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(mod, data, }\DataTypeTok{res =} \StringTok{"y"}\NormalTok{, }\DataTypeTok{pos =} \DecValTok{1}\NormalTok{, }\DataTypeTok{neg =} \DecValTok{0}\NormalTok{, }\DataTypeTok{cut =} \FloatTok{0.5}\NormalTok{) \{}
\NormalTok{  probs =}\StringTok{ }\KeywordTok{predict}\NormalTok{(mod, }\DataTypeTok{newdata =}\NormalTok{ data, }\DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}
  \KeywordTok{ifelse}\NormalTok{(probs }\OperatorTok{>}\StringTok{ }\NormalTok{cut, pos, neg)}
\NormalTok{\}}

\NormalTok{test_pred_}\DecValTok{10}\NormalTok{ =}\StringTok{ }\KeywordTok{get_logistic_pred}\NormalTok{(bank_lr_aic_transform, }\DataTypeTok{data =}\NormalTok{ test, }\DataTypeTok{res =} \StringTok{"default"}\NormalTok{, }
                                 \DataTypeTok{pos =} \DecValTok{1}\NormalTok{, }\DataTypeTok{neg =} \DecValTok{0}\NormalTok{, }\DataTypeTok{cut =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{test_pred_}\DecValTok{30}\NormalTok{ =}\StringTok{ }\KeywordTok{get_logistic_pred}\NormalTok{(bank_lr_aic_transform, }\DataTypeTok{data =}\NormalTok{ test, }\DataTypeTok{res =} \StringTok{"default"}\NormalTok{, }
                                 \DataTypeTok{pos =} \DecValTok{1}\NormalTok{, }\DataTypeTok{neg =} \DecValTok{0}\NormalTok{, }\DataTypeTok{cut =} \FloatTok{0.3}\NormalTok{)}
\NormalTok{test_pred_}\DecValTok{40}\NormalTok{ =}\StringTok{ }\KeywordTok{get_logistic_pred}\NormalTok{(bank_lr_aic_transform, }\DataTypeTok{data =}\NormalTok{ test, }\DataTypeTok{res =} \StringTok{"default"}\NormalTok{, }
                                 \DataTypeTok{pos =} \DecValTok{1}\NormalTok{, }\DataTypeTok{neg =} \DecValTok{0}\NormalTok{, }\DataTypeTok{cut =} \FloatTok{0.4}\NormalTok{)}
\NormalTok{test_pred_}\DecValTok{50}\NormalTok{ =}\StringTok{ }\KeywordTok{get_logistic_pred}\NormalTok{(bank_lr_aic_transform, }\DataTypeTok{data =}\NormalTok{ test, }\DataTypeTok{res =} \StringTok{"default"}\NormalTok{, }
                                 \DataTypeTok{pos =} \DecValTok{1}\NormalTok{, }\DataTypeTok{neg =} \DecValTok{0}\NormalTok{, }\DataTypeTok{cut =} \FloatTok{0.5}\NormalTok{)}
\NormalTok{test_pred_}\DecValTok{60}\NormalTok{ =}\StringTok{ }\KeywordTok{get_logistic_pred}\NormalTok{(bank_lr_aic_transform, }\DataTypeTok{data =}\NormalTok{ test, }\DataTypeTok{res =} \StringTok{"default"}\NormalTok{, }
                                 \DataTypeTok{pos =} \DecValTok{1}\NormalTok{, }\DataTypeTok{neg =} \DecValTok{0}\NormalTok{, }\DataTypeTok{cut =} \FloatTok{0.6}\NormalTok{)}
\NormalTok{test_pred_}\DecValTok{90}\NormalTok{ =}\StringTok{ }\KeywordTok{get_logistic_pred}\NormalTok{(bank_lr_aic_transform, }\DataTypeTok{data =}\NormalTok{ test, }\DataTypeTok{res =} \StringTok{"default"}\NormalTok{, }
                                 \DataTypeTok{pos =} \DecValTok{1}\NormalTok{, }\DataTypeTok{neg =} \DecValTok{0}\NormalTok{, }\DataTypeTok{cut =} \FloatTok{0.9}\NormalTok{)}

\NormalTok{test_tab_}\DecValTok{10}\NormalTok{ =}\StringTok{ }\KeywordTok{table}\NormalTok{(}\DataTypeTok{predicted =}\NormalTok{ test_pred_}\DecValTok{10}\NormalTok{, }\DataTypeTok{actual =}\NormalTok{ test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{test_tab_}\DecValTok{30}\NormalTok{ =}\StringTok{ }\KeywordTok{table}\NormalTok{(}\DataTypeTok{predicted =}\NormalTok{ test_pred_}\DecValTok{30}\NormalTok{, }\DataTypeTok{actual =}\NormalTok{ test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{test_tab_}\DecValTok{40}\NormalTok{ =}\StringTok{ }\KeywordTok{table}\NormalTok{(}\DataTypeTok{predicted =}\NormalTok{ test_pred_}\DecValTok{40}\NormalTok{, }\DataTypeTok{actual =}\NormalTok{ test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{test_tab_}\DecValTok{50}\NormalTok{ =}\StringTok{ }\KeywordTok{table}\NormalTok{(}\DataTypeTok{predicted =}\NormalTok{ test_pred_}\DecValTok{50}\NormalTok{, }\DataTypeTok{actual =}\NormalTok{ test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{test_tab_}\DecValTok{60}\NormalTok{ =}\StringTok{ }\KeywordTok{table}\NormalTok{(}\DataTypeTok{predicted =}\NormalTok{ test_pred_}\DecValTok{60}\NormalTok{, }\DataTypeTok{actual =}\NormalTok{ test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{test_tab_}\DecValTok{90}\NormalTok{ =}\StringTok{ }\KeywordTok{table}\NormalTok{(}\DataTypeTok{predicted =}\NormalTok{ test_pred_}\DecValTok{90}\NormalTok{, }\DataTypeTok{actual =}\NormalTok{ test}\OperatorTok{$}\NormalTok{y)}

\NormalTok{test_con_mat_}\DecValTok{10}\NormalTok{ =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(test_tab_}\DecValTok{10}\NormalTok{, }\DataTypeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{test_con_mat_}\DecValTok{30}\NormalTok{ =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(test_tab_}\DecValTok{30}\NormalTok{, }\DataTypeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{test_con_mat_}\DecValTok{40}\NormalTok{ =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(test_tab_}\DecValTok{40}\NormalTok{, }\DataTypeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{test_con_mat_}\DecValTok{50}\NormalTok{ =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(test_tab_}\DecValTok{50}\NormalTok{, }\DataTypeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{test_con_mat_}\DecValTok{60}\NormalTok{ =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(test_tab_}\DecValTok{60}\NormalTok{, }\DataTypeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{test_con_mat_}\DecValTok{90}\NormalTok{ =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(test_tab_}\DecValTok{90}\NormalTok{, }\DataTypeTok{positive =} \StringTok{"1"}\NormalTok{)}

\NormalTok{metrics =}\StringTok{ }\KeywordTok{rbind}\NormalTok{(}
  
  \KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{]),}
   \KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{30}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{30}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{30}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{]),}
   \KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{40}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{40}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{40}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{]),}
  
  \KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{50}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{50}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{50}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{]),}
   \KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{60}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{60}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{60}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{]),}
  
  \KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{90}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{90}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{], }
\NormalTok{    test_con_mat_}\DecValTok{90}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{])}

\NormalTok{)}

\KeywordTok{rownames}\NormalTok{(metrics) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"c = 0.10"}\NormalTok{, }\StringTok{"c = 0.30"}\NormalTok{,}\StringTok{"c = 0.40"}\NormalTok{,}\StringTok{"c = 0.50"}\NormalTok{,}\StringTok{"c = 0.60"}\NormalTok{, }\StringTok{"c = 0.90"}\NormalTok{)}
\NormalTok{metrics}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Accuracy Sensitivity Specificity
## c = 0.10 0.8454693   0.8740741   0.8419619
## c = 0.30 0.9037217   0.6222222   0.9382380
## c = 0.40 0.9101942   0.5777778   0.9509537
## c = 0.50 0.9118123   0.5037037   0.9618529
## c = 0.60 0.9101942   0.4148148   0.9709355
## c = 0.90 0.8980583   0.1259259   0.9927339
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_prob =}\StringTok{ }\KeywordTok{predict}\NormalTok{(bank_lr_aic_transform, }\DataTypeTok{newdata =}\NormalTok{ test, }\DataTypeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{test_roc =}\StringTok{ }\KeywordTok{roc}\NormalTok{(test}\OperatorTok{$}\NormalTok{y }\OperatorTok{~}\StringTok{ }\NormalTok{test_prob, }\DataTypeTok{plot =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{print.auc =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Setting levels: control = 0, case = 1
\end{verbatim}

\begin{verbatim}
## Setting direction: controls < cases
\end{verbatim}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-37-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(}\KeywordTok{auc}\NormalTok{(test_roc))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "auc"     "numeric"
\end{verbatim}

\begin{itemize}
\tightlist
\item
  With the best chosen model from logistic regresion, we have AUC above
  0.9 and the ratio of Sensitity and Specificity is good as well.
\end{itemize}

\hypertarget{model-2-random-forest}{%
\subsubsection{Model 2: Random Forest}\label{model-2-random-forest}}

\begin{itemize}
\tightlist
\item
  We have chosen Random Forest model (ensemble) to do binary
  classification to predict whether customer will subscribe to term
  deposit or not.
\end{itemize}

\hypertarget{model-using-all-predictors}{%
\paragraph{model using all
predictors}\label{model-using-all-predictors}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_rf<-}\KeywordTok{randomForest}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{.  , }\DataTypeTok{data=}\NormalTok{train, }\DataTypeTok{mtry=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Fitted model details
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_rf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
##  randomForest(formula = y ~ ., data = train, mtry = 3) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 8.72%
## Confusion matrix:
##      0   1 class.error
## 0 2507  65  0.02527216
## 1  187 130  0.58990536
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Dotchart of variable importance as measured by a Random Forest
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{varImpPlot}\NormalTok{(model_rf)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-40-1.pdf}

\begin{itemize}
\tightlist
\item
  Confusion Matrix for Training Dataset
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred_train<-}\KeywordTok{predict}\NormalTok{(model_rf,train)}
\KeywordTok{confusionMatrix}\NormalTok{(train}\OperatorTok{$}\NormalTok{y,pred_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 2572    0
##          1    6  311
##                                           
##                Accuracy : 0.9979          
##                  95% CI : (0.9955, 0.9992)
##     No Information Rate : 0.8924          
##     P-Value [Acc > NIR] : < 2e-16         
##                                           
##                   Kappa : 0.9893          
##                                           
##  Mcnemar's Test P-Value : 0.04123         
##                                           
##             Sensitivity : 0.9977          
##             Specificity : 1.0000          
##          Pos Pred Value : 1.0000          
##          Neg Pred Value : 0.9811          
##              Prevalence : 0.8924          
##          Detection Rate : 0.8903          
##    Detection Prevalence : 0.8903          
##       Balanced Accuracy : 0.9988          
##                                           
##        'Positive' Class : 0               
## 
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Confusion Matrix for Test Dataset
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred_test1<-}\KeywordTok{predict}\NormalTok{(model_rf,test)}
\KeywordTok{confusionMatrix}\NormalTok{(test}\OperatorTok{$}\NormalTok{y,pred_test1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    0    1
##          0 1053   48
##          1   77   58
##                                           
##                Accuracy : 0.8989          
##                  95% CI : (0.8807, 0.9151)
##     No Information Rate : 0.9142          
##     P-Value [Acc > NIR] : 0.97401         
##                                           
##                   Kappa : 0.4262          
##                                           
##  Mcnemar's Test P-Value : 0.01227         
##                                           
##             Sensitivity : 0.9319          
##             Specificity : 0.5472          
##          Pos Pred Value : 0.9564          
##          Neg Pred Value : 0.4296          
##              Prevalence : 0.9142          
##          Detection Rate : 0.8519          
##    Detection Prevalence : 0.8908          
##       Balanced Accuracy : 0.7395          
##                                           
##        'Positive' Class : 0               
## 
\end{verbatim}

\hypertarget{plot-roc-curve-tpr-vs-fpr}{%
\paragraph{Plot ROC curve (TPR vs
FPR)}\label{plot-roc-curve-tpr-vs-fpr}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{pr_train =}\StringTok{ }\KeywordTok{prediction}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(pred_train),train}\OperatorTok{$}\NormalTok{y)}
\NormalTok{prf_train =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_train, }\DataTypeTok{measure =} \StringTok{"tpr"}\NormalTok{, }\DataTypeTok{x.measure =} \StringTok{"fpr"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(prf_train)}

\NormalTok{pr_test1 =}\StringTok{ }\KeywordTok{prediction}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(pred_test1),test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{prf_test1 =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_test1, }\DataTypeTok{measure =} \StringTok{"tpr"}\NormalTok{,}\DataTypeTok{x.measure =} \StringTok{"fpr"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(prf_test1)}

\KeywordTok{mtext}\NormalTok{(}\StringTok{"ROC curve (TPR vs FPR) for Train Vs Test"}\NormalTok{, }\DataTypeTok{side =} \DecValTok{3}\NormalTok{, }\DataTypeTok{line =} \DecValTok{-1}\NormalTok{, }\DataTypeTok{outer =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-43-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auc_train =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_train, }\DataTypeTok{measure =} \StringTok{"auc"}\NormalTok{)}
\NormalTok{auc_test1 =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_test1, }\DataTypeTok{measure =} \StringTok{"auc"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{tuning-random-forest-model}{%
\paragraph{Tuning Random Forest
Model}\label{tuning-random-forest-model}}

\begin{itemize}
\tightlist
\item
  Need to find out optimum varible split for each decision tree by
  running cross validation. In general, \texttt{mtry} value is
  \(\sqrt(p)\) where p is total number of predictors. We would use train
  function from caret library to find out the optimum split.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oob =}\StringTok{ }\KeywordTok{trainControl}\NormalTok{(}\DataTypeTok{method =} \StringTok{"oob"}\NormalTok{)}
\NormalTok{cv_}\DecValTok{5}\NormalTok{ =}\StringTok{ }\KeywordTok{trainControl}\NormalTok{(}\DataTypeTok{method =} \StringTok{"cv"}\NormalTok{, }\DataTypeTok{number =} \DecValTok{5}\NormalTok{)}

\NormalTok{rf_mtry =}\StringTok{ }\KeywordTok{ceiling}\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{20}\NormalTok{))}
\NormalTok{rf_grid =}\StringTok{  }\KeywordTok{expand.grid}\NormalTok{(}\DataTypeTok{mtry =} \DecValTok{1}\OperatorTok{:}\NormalTok{rf_mtry)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{bank_rf_tune =}\StringTok{ }\KeywordTok{train}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{. , }\DataTypeTok{data =}\NormalTok{ train,}
                     \DataTypeTok{method =} \StringTok{"rf"}\NormalTok{,}
                     \DataTypeTok{trControl =}\NormalTok{ oob,}
                     \DataTypeTok{verbose =} \OtherTok{FALSE}\NormalTok{,}
                     \DataTypeTok{tuneGrid =}\NormalTok{ rf_grid)}
\NormalTok{bank_rf_tune}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Random Forest 
## 
## 2889 samples
##   22 predictor
##    2 classes: '0', '1' 
## 
## No pre-processing
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##   1     0.8902735  0.0000000
##   2     0.9023884  0.2265780
##   3     0.9065421  0.3041771
##   4     0.9106957  0.3776660
##   5     0.9131187  0.4238403
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 5.
\end{verbatim}

\hypertarget{metrics-for-best-random-forest-model}{%
\paragraph{Metrics for best Random Forest
Model}\label{metrics-for-best-random-forest-model}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_rf_best<-}\KeywordTok{randomForest}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{.  , }\DataTypeTok{data=}\NormalTok{train, }\DataTypeTok{mtry=}\NormalTok{bank_rf_tune}\OperatorTok{$}\NormalTok{bestTune}\OperatorTok{$}\NormalTok{mtry[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred_train<-}\KeywordTok{predict}\NormalTok{(model_rf_best,train)}
\NormalTok{pred_test1<-}\KeywordTok{predict}\NormalTok{(model_rf_best,test)}
\NormalTok{train_cm =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(train}\OperatorTok{$}\NormalTok{y,pred_train)}
\NormalTok{test1_cm =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(test}\OperatorTok{$}\NormalTok{y,pred_test1)}

\NormalTok{metrics =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(train_cm}\OperatorTok{$}\NormalTok{byClass, test1_cm}\OperatorTok{$}\NormalTok{byClass)}
\NormalTok{acc =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(train_cm}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{],test1_cm}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{])}
\NormalTok{auc =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(auc_train}\OperatorTok{@}\NormalTok{y.values,auc_test1}\OperatorTok{@}\NormalTok{y.values)}
\KeywordTok{rownames}\NormalTok{(auc) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Area Under Curve"}\NormalTok{)}
\NormalTok{result =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{rbind}\NormalTok{(acc,auc,metrics))}

\KeywordTok{colnames}\NormalTok{(result) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Train"}\NormalTok{,}\StringTok{"Test"}\NormalTok{)}
\KeywordTok{kable}\NormalTok{(result) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{bootstrap_options =} \KeywordTok{c}\NormalTok{(}\StringTok{"striped"}\NormalTok{, }\StringTok{"hover"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}{l|l|l}
\hline
  & Train & Test\\
\hline
Accuracy & 1 & 0.905339805825243\\
\hline
Area Under Curve & 0.990536277602524 & 0.693016449692199\\
\hline
Sensitivity & 1 & 0.942446043165468\\
\hline
Specificity & 1 & 0.57258064516129\\
\hline
Pos Pred Value & 1 & 0.951861943687557\\
\hline
Neg Pred Value & 1 & 0.525925925925926\\
\hline
Precision & 1 & 0.951861943687557\\
\hline
Recall & 1 & 0.942446043165468\\
\hline
F1 & 1 & 0.94713059195662\\
\hline
Prevalence & 0.890273451021115 & 0.899676375404531\\
\hline
Detection Rate & 0.890273451021115 & 0.84789644012945\\
\hline
Detection Prevalence & 0.890273451021115 & 0.890776699029126\\
\hline
Balanced Accuracy & 1 & 0.757513344163379\\
\hline
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# to be pulled by final result session}
\NormalTok{test1_cm_rf =}\StringTok{ }\NormalTok{test1_cm}
\NormalTok{auc_test1_rf =}\StringTok{ }\NormalTok{auc_test1}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-3-adaptive-boosting}{%
\subsubsection{Model 3: Adaptive
Boosting}\label{model-3-adaptive-boosting}}

\begin{itemize}
\item
  AdaBoost is an ensemble learning method (also known as
  ``meta-learning'') which was initially created to increase the
  efficiency of binary classifiers. AdaBoost uses an iterative approach
  to learn from the mistakes of weak classifiers, and turn them into
  strong ones. We will be using the library \texttt{ada} for the same.
  This model have built in feature selection.
\item
  Build the model with default parameter values
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_model_ada =}\StringTok{ }\KeywordTok{ada}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{train,}\DataTypeTok{loss=}\StringTok{'exponential'}\NormalTok{, }\DataTypeTok{type=}\StringTok{'discrete'}\NormalTok{, }\DataTypeTok{iter =} \DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_model_ada}\OperatorTok{$}\NormalTok{confusion}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Final Prediction
## True value    0    1
##          0 2547   25
##          1   68  249
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(bank_model_ada}\OperatorTok{$}\NormalTok{confusion[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(bank_model_ada}\OperatorTok{$}\NormalTok{confusion[,}\DecValTok{2}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9087591
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Below plot shows training error vs iteration where training error
  reduces and stabilizes as iteration grows
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bank_model_ada)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-49-1.pdf}

\begin{itemize}
\tightlist
\item
  Plot of variables ordered by the variable importance measure
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{varplot}\NormalTok{(bank_model_ada)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-50-1.pdf}

\begin{itemize}
\tightlist
\item
  In the above training error plot the error rate reduced at minimal
  \textasciitilde25 and then slightly increased. So lets try with lesser
  iterations and measure the metrics
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_model_ada25 =}\StringTok{ }\KeywordTok{ada}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{train,}\DataTypeTok{loss=}\StringTok{'exponential'}\NormalTok{, }\DataTypeTok{type=}\StringTok{'discrete'}\NormalTok{, }\DataTypeTok{iter =} \DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Confustion Matrix for a Ada Model with 25 iterations
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_model_ada25}\OperatorTok{$}\NormalTok{confusion}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Final Prediction
## True value    0    1
##          0 2537   35
##          1   89  228
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(bank_model_ada25}\OperatorTok{$}\NormalTok{confusion[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(bank_model_ada25}\OperatorTok{$}\NormalTok{confusion[,}\DecValTok{2}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8669202
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Build model with 100 iterations
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_model_ada100 =}\StringTok{ }\KeywordTok{ada}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{train,}\DataTypeTok{loss=}\StringTok{'exponential'}\NormalTok{, }\DataTypeTok{type=}\StringTok{'discrete'}\NormalTok{, }\DataTypeTok{iter =} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Confustion Matrix for a Ada Model with 100 iterations
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bank_model_ada100}\OperatorTok{$}\NormalTok{confusion}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Final Prediction
## True value    0    1
##          0 2569    3
##          1   37  280
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(bank_model_ada100}\OperatorTok{$}\NormalTok{confusion[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(bank_model_ada100}\OperatorTok{$}\NormalTok{confusion[,}\DecValTok{2}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9893993
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Below plot shows training error vs iteration where training error
  reduces and stabilizes as iteration grows
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bank_model_ada100)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-55-1.pdf}

\begin{itemize}
\tightlist
\item
  Since our dataset has class imbalance problem where less positive
  cases and lot of negative cases. Lets use resampled training data
  using \texttt{SMOTE} and \texttt{ROSE} function for training.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_ada_smote =}\StringTok{ }\KeywordTok{ada}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{smote_train,}\DataTypeTok{loss=}\StringTok{'exponential'}\NormalTok{, }\DataTypeTok{type=}\StringTok{'discrete'}\NormalTok{,}\DataTypeTok{iter=}\DecValTok{100}\NormalTok{)}

\NormalTok{model_ada_smote}\OperatorTok{$}\NormalTok{confusion}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Final Prediction
## True value    0    1
##          0 1250   18
##          1   15  936
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(model_ada_smote}\OperatorTok{$}\NormalTok{confusion[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(model_ada_smote}\OperatorTok{$}\NormalTok{confusion[,}\DecValTok{2}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9811321
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model_ada_rose =}\StringTok{ }\KeywordTok{ada}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data=}\NormalTok{rose_train,}\DataTypeTok{loss=}\StringTok{'exponential'}\NormalTok{, }\DataTypeTok{type=}\StringTok{'discrete'}\NormalTok{,}\DataTypeTok{iter=}\DecValTok{100}\NormalTok{)}

\NormalTok{model_ada_rose}\OperatorTok{$}\NormalTok{confusion}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Final Prediction
## True value    0    1
##          0 1452   16
##          1   26 1395
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(model_ada_rose}\OperatorTok{$}\NormalTok{confusion[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(model_ada_rose}\OperatorTok{$}\NormalTok{confusion[,}\DecValTok{2}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9886605
\end{verbatim}

\begin{itemize}
\item
  We see that our accuracy increased after our using resampled data
  using smote and rose function.
\item
  Plot TPR VS FPR for Training and Test Dataset
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred_train =}\StringTok{ }\KeywordTok{predict}\NormalTok{(bank_model_ada100, train)}
\NormalTok{train_cm =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(train}\OperatorTok{$}\NormalTok{y,}\KeywordTok{as.factor}\NormalTok{(pred_train))}
\NormalTok{pred_test =}\StringTok{ }\KeywordTok{predict}\NormalTok{(bank_model_ada100, test)}
\NormalTok{test1_cm=}\KeywordTok{confusionMatrix}\NormalTok{(test}\OperatorTok{$}\NormalTok{y,}\KeywordTok{as.factor}\NormalTok{(pred_test))}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{pr_train =}\StringTok{ }\KeywordTok{prediction}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(pred_train),train}\OperatorTok{$}\NormalTok{y)}
\NormalTok{prf_train =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_train, }\DataTypeTok{measure =} \StringTok{"tpr"}\NormalTok{, }\DataTypeTok{x.measure =} \StringTok{"fpr"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(prf_train)}

\NormalTok{pr_test1 =}\StringTok{ }\KeywordTok{prediction}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(pred_test),test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{prf_test1 =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_test1, }\DataTypeTok{measure =} \StringTok{"tpr"}\NormalTok{,}\DataTypeTok{x.measure =} \StringTok{"fpr"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(prf_test1)}

\KeywordTok{mtext}\NormalTok{(}\StringTok{"ROC curve (TPR vs FPR) for Train Vs Test"}\NormalTok{, }\DataTypeTok{side =} \DecValTok{3}\NormalTok{, }\DataTypeTok{line =} \DecValTok{-1}\NormalTok{, }\DataTypeTok{outer =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-57-1.pdf}

\begin{itemize}
\tightlist
\item
  Metrics for Training VS Testing Dataset
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auc_train =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_train, }\DataTypeTok{measure =} \StringTok{"auc"}\NormalTok{)}
\NormalTok{auc_test1 =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_test1, }\DataTypeTok{measure =} \StringTok{"auc"}\NormalTok{)}

\NormalTok{metrics =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(train_cm}\OperatorTok{$}\NormalTok{byClass, test1_cm}\OperatorTok{$}\NormalTok{byClass)}
\NormalTok{acc =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(train_cm}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{],test1_cm}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{])}
\NormalTok{auc =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(auc_train}\OperatorTok{@}\NormalTok{y.values,auc_test1}\OperatorTok{@}\NormalTok{y.values)}
\KeywordTok{rownames}\NormalTok{(auc) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Area Under Curve"}\NormalTok{)}
\NormalTok{result =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{rbind}\NormalTok{(acc,auc,metrics))}

\KeywordTok{colnames}\NormalTok{(result) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Train"}\NormalTok{,}\StringTok{"Test"}\NormalTok{)}
\KeywordTok{kable}\NormalTok{(result) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{bootstrap_options =} \KeywordTok{c}\NormalTok{(}\StringTok{"striped"}\NormalTok{, }\StringTok{"hover"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}{l|l|l}
\hline
  & Train & Test\\
\hline
Accuracy & 0.986154378677743 & 0.902912621359223\\
\hline
Area Under Curve & 0.941057174816392 & 0.744030679180543\\
\hline
Sensitivity & 0.985801995395242 & 0.943891402714932\\
\hline
Specificity & 0.989399293286219 & 0.557251908396947\\
\hline
Pos Pred Value & 0.998833592534992 & 0.947320617620345\\
\hline
Neg Pred Value & 0.883280757097792 & 0.540740740740741\\
\hline
Precision & 0.998833592534992 & 0.947320617620345\\
\hline
Recall & 0.985801995395242 & 0.943891402714932\\
\hline
F1 & 0.992275009656238 & 0.945602901178604\\
\hline
Prevalence & 0.902042229145033 & 0.894012944983819\\
\hline
Detection Rate & 0.889235029421945 & 0.843851132686084\\
\hline
Detection Prevalence & 0.890273451021115 & 0.890776699029126\\
\hline
Balanced Accuracy & 0.98760064434073 & 0.750571655555939\\
\hline
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# to be pull by final result session}
\NormalTok{test1_cm_ab =}\StringTok{ }\NormalTok{test1_cm}
\NormalTok{auc_test1_ab =}\StringTok{ }\NormalTok{auc_test1}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Plot TPR vs FPR (SMOTED TRAIN vs TEST)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred_train =}\StringTok{ }\KeywordTok{predict}\NormalTok{(model_ada_smote, smote_train)}
\NormalTok{train_cm =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(smote_train}\OperatorTok{$}\NormalTok{y,}\KeywordTok{as.factor}\NormalTok{(pred_train))}
\NormalTok{pred_test1 =}\StringTok{ }\KeywordTok{predict}\NormalTok{(model_ada_smote, test)}
\NormalTok{test1_cm=}\KeywordTok{confusionMatrix}\NormalTok{(test}\OperatorTok{$}\NormalTok{y,}\KeywordTok{as.factor}\NormalTok{(pred_test1))}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{pr_train =}\StringTok{ }\KeywordTok{prediction}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(pred_train),smote_train}\OperatorTok{$}\NormalTok{y)}
\NormalTok{prf_train =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_train, }\DataTypeTok{measure =} \StringTok{"tpr"}\NormalTok{, }\DataTypeTok{x.measure =} \StringTok{"fpr"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(prf_train)}

\NormalTok{pr_test1 =}\StringTok{ }\KeywordTok{prediction}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(pred_test1),test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{prf_test1 =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_test1, }\DataTypeTok{measure =} \StringTok{"tpr"}\NormalTok{,}\DataTypeTok{x.measure =} \StringTok{"fpr"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(prf_test1)}

\KeywordTok{mtext}\NormalTok{(}\StringTok{"ROC curve (TPR vs FPR) for Train Vs Test"}\NormalTok{, }\DataTypeTok{side =} \DecValTok{3}\NormalTok{, }\DataTypeTok{line =} \DecValTok{-1}\NormalTok{, }\DataTypeTok{outer =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-59-1.pdf}

\begin{itemize}
\tightlist
\item
  Metrics for SMOTED TRAIN vs TEST
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auc_train =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_train, }\DataTypeTok{measure =} \StringTok{"auc"}\NormalTok{)}
\NormalTok{auc_test1 =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_test1, }\DataTypeTok{measure =} \StringTok{"auc"}\NormalTok{)}

\NormalTok{metrics =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(train_cm}\OperatorTok{$}\NormalTok{byClass, test1_cm}\OperatorTok{$}\NormalTok{byClass)}
\NormalTok{acc =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(train_cm}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{],test1_cm}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{])}
\NormalTok{auc =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(auc_train}\OperatorTok{@}\NormalTok{y.values,auc_test1}\OperatorTok{@}\NormalTok{y.values)}
\KeywordTok{rownames}\NormalTok{(auc) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Area Under Curve"}\NormalTok{)}
\NormalTok{result =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{rbind}\NormalTok{(acc,auc,metrics))}

\KeywordTok{colnames}\NormalTok{(result) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Train"}\NormalTok{,}\StringTok{"Test"}\NormalTok{)}
\KeywordTok{kable}\NormalTok{(result) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{bootstrap_options =} \KeywordTok{c}\NormalTok{(}\StringTok{"striped"}\NormalTok{, }\StringTok{"hover"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}{l|l|l}
\hline
  & Train & Test\\
\hline
Accuracy & 0.985128436232537 & 0.879449838187702\\
\hline
Area Under Curve & 0.985015772870662 & 0.82184882430114\\
\hline
Sensitivity & 0.988142292490119 & 0.966666666666667\\
\hline
Specificity & 0.981132075471698 & 0.467592592592593\\
\hline
Pos Pred Value & 0.985804416403785 & 0.895549500454133\\
\hline
Neg Pred Value & 0.984227129337539 & 0.748148148148148\\
\hline
Precision & 0.985804416403785 & 0.895549500454133\\
\hline
Recall & 0.988142292490119 & 0.966666666666667\\
\hline
F1 & 0.986971969996052 & 0.92975011786893\\
\hline
Prevalence & 0.570076611086075 & 0.825242718446602\\
\hline
Detection Rate & 0.563316809373592 & 0.797734627831715\\
\hline
Detection Prevalence & 0.571428571428571 & 0.890776699029126\\
\hline
Balanced Accuracy & 0.984637183980908 & 0.71712962962963\\
\hline
\end{tabular}
\end{table}

\begin{itemize}
\tightlist
\item
  Plot TPR vs FPR (ROSE TRAIN vs TEST)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred_train =}\StringTok{ }\KeywordTok{predict}\NormalTok{(model_ada_rose, rose_train)}
\NormalTok{train_cm =}\StringTok{ }\KeywordTok{confusionMatrix}\NormalTok{(rose_train}\OperatorTok{$}\NormalTok{y,}\KeywordTok{as.factor}\NormalTok{(pred_train))}
\NormalTok{pred_test1 =}\StringTok{ }\KeywordTok{predict}\NormalTok{(model_ada_rose, test)}
\NormalTok{test1_cm=}\KeywordTok{confusionMatrix}\NormalTok{(test}\OperatorTok{$}\NormalTok{y,}\KeywordTok{as.factor}\NormalTok{(pred_test1))}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{pr_train =}\StringTok{ }\KeywordTok{prediction}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(pred_train),rose_train}\OperatorTok{$}\NormalTok{y)}
\NormalTok{prf_train =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_train, }\DataTypeTok{measure =} \StringTok{"tpr"}\NormalTok{, }\DataTypeTok{x.measure =} \StringTok{"fpr"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(prf_train)}

\NormalTok{pr_test1 =}\StringTok{ }\KeywordTok{prediction}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(pred_test1),test}\OperatorTok{$}\NormalTok{y)}
\NormalTok{prf_test1 =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_test1, }\DataTypeTok{measure =} \StringTok{"tpr"}\NormalTok{,}\DataTypeTok{x.measure =} \StringTok{"fpr"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(prf_test1)}

\KeywordTok{mtext}\NormalTok{(}\StringTok{"ROC curve (TPR vs FPR) for Train Vs Test"}\NormalTok{, }\DataTypeTok{side =} \DecValTok{3}\NormalTok{, }\DataTypeTok{line =} \DecValTok{-1}\NormalTok{, }\DataTypeTok{outer =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-analysis-project-report_files/figure-latex/unnamed-chunk-61-1.pdf}

\begin{itemize}
\tightlist
\item
  Metrics for ROSE Train vs Test
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auc_train =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_train, }\DataTypeTok{measure =} \StringTok{"auc"}\NormalTok{)}
\NormalTok{auc_test1 =}\StringTok{ }\KeywordTok{performance}\NormalTok{(pr_test1, }\DataTypeTok{measure =} \StringTok{"auc"}\NormalTok{)}

\NormalTok{metrics =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(train_cm}\OperatorTok{$}\NormalTok{byClass, test1_cm}\OperatorTok{$}\NormalTok{byClass)}
\NormalTok{acc =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(train_cm}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{],test1_cm}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{])}
\NormalTok{auc =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(auc_train}\OperatorTok{@}\NormalTok{y.values,auc_test1}\OperatorTok{@}\NormalTok{y.values)}
\KeywordTok{rownames}\NormalTok{(auc) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Area Under Curve"}\NormalTok{)}
\NormalTok{result =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{rbind}\NormalTok{(acc,auc,metrics))}

\KeywordTok{colnames}\NormalTok{(result) =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Train"}\NormalTok{,}\StringTok{"Test"}\NormalTok{)}
\KeywordTok{kable}\NormalTok{(result) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{kable_styling}\NormalTok{(}\DataTypeTok{bootstrap_options =} \KeywordTok{c}\NormalTok{(}\StringTok{"striped"}\NormalTok{, }\StringTok{"hover"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}{l|l|l}
\hline
  & Train & Test\\
\hline
Accuracy & 0.98546209761163 & 0.90453074433657\\
\hline
Area Under Curve & 0.985401921738347 & 0.709193662327177\\
\hline
Sensitivity & 0.982408660351827 & 0.935341009743135\\
\hline
Specificity & 0.988660524450744 & 0.579439252336449\\
\hline
Pos Pred Value & 0.989100817438692 & 0.959128065395095\\
\hline
Neg Pred Value & 0.981703026038001 & 0.459259259259259\\
\hline
Precision & 0.989100817438692 & 0.959128065395095\\
\hline
Recall & 0.982408660351827 & 0.935341009743135\\
\hline
F1 & 0.985743380855397 & 0.947085201793722\\
\hline
Prevalence & 0.51159570785739 & 0.913430420711974\\
\hline
Detection Rate & 0.502596053997923 & 0.854368932038835\\
\hline
Detection Prevalence & 0.508134302526826 & 0.890776699029126\\
\hline
Balanced Accuracy & 0.985534592401285 & 0.757390131039792\\
\hline
\end{tabular}
\end{table}

\hypertarget{results}{%
\subsubsection{Results}\label{results}}

\hypertarget{compare-models-test-and-train-accuracy}{%
\paragraph{Compare Models (Test and Train
Accuracy)}\label{compare-models-test-and-train-accuracy}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# compare Accuracy and ROC}
\NormalTok{compare <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Method =} \KeywordTok{c}\NormalTok{(}\StringTok{'Logistic Regression (cutoff = 0.1)'}\NormalTok{, }\StringTok{'Random Forest (mtry = 5)'}\NormalTok{, }\StringTok{'Adaptive boosting'}\NormalTok{), }\DataTypeTok{Accuracy =} \OtherTok{NA}\NormalTok{, }\DataTypeTok{Sensitivity =} \OtherTok{NA}\NormalTok{, }\DataTypeTok{Specificity =} \OtherTok{NA}\NormalTok{, }\DataTypeTok{Precision =} \OtherTok{NA}\NormalTok{, }\DataTypeTok{Recall =} \OtherTok{NA}\NormalTok{, }\DataTypeTok{FScore =} \OtherTok{NA}\NormalTok{, }\StringTok{'ROC AUC'}\NormalTok{ =}\StringTok{ }\OtherTok{NA}\NormalTok{)}

\NormalTok{compare}\OperatorTok{$}\NormalTok{Accuracy <-}\StringTok{ }\KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{overall[}\StringTok{"Accuracy"}\NormalTok{], test1_cm_rf}\OperatorTok{$}\NormalTok{overall[}\StringTok{'Accuracy'}\NormalTok{],test1_cm_ab}\OperatorTok{$}\NormalTok{overall[}\StringTok{'Accuracy'}\NormalTok{])}

\NormalTok{compare}\OperatorTok{$}\NormalTok{Sensitivity <-}\StringTok{ }\KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{], test1_cm_rf}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'Sensitivity'}\NormalTok{],test1_cm_ab}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'Sensitivity'}\NormalTok{])}

\NormalTok{compare}\OperatorTok{$}\NormalTok{Specificity <-}\StringTok{ }\KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{], test1_cm_rf}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'Specificity'}\NormalTok{],test1_cm_ab}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'Specificity'}\NormalTok{])}

\NormalTok{compare}\OperatorTok{$}\NormalTok{Precision <-}\StringTok{ }\KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Precision"}\NormalTok{], test1_cm_rf}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'Precision'}\NormalTok{],test1_cm_ab}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'Precision'}\NormalTok{])}

\NormalTok{compare}\OperatorTok{$}\NormalTok{Recall <-}\StringTok{ }\KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Recall"}\NormalTok{], test1_cm_rf}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'Recall'}\NormalTok{],test1_cm_ab}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'Recall'}\NormalTok{])}

\NormalTok{compare}\OperatorTok{$}\NormalTok{FScore <-}\StringTok{ }\KeywordTok{c}\NormalTok{(test_con_mat_}\DecValTok{10}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"F1"}\NormalTok{], test1_cm_rf}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'F1'}\NormalTok{],test1_cm_ab}\OperatorTok{$}\NormalTok{byClass[}\StringTok{'F1'}\NormalTok{])}

\NormalTok{compare}\OperatorTok{$}\NormalTok{ROC.AUC <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{auc}\NormalTok{(test_roc), auc_test1_rf}\OperatorTok{@}\NormalTok{y.values, auc_test1_ab}\OperatorTok{@}\NormalTok{y.values)}

\KeywordTok{kable_styling}\NormalTok{(}\KeywordTok{kable}\NormalTok{(compare),}\KeywordTok{c}\NormalTok{(}\StringTok{"striped"}\NormalTok{,}\StringTok{"bordered"}\NormalTok{), }\DataTypeTok{full_width =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{table}[H]
\centering
\begin{tabular}{l|r|r|r|r|r|r|l}
\hline
Method & Accuracy & Sensitivity & Specificity & Precision & Recall & FScore & ROC.AUC\\
\hline
Logistic Regression (cutoff = 0.1) & 0.8454693 & 0.8740741 & 0.8419619 & 0.4041096 & 0.8740741 & 0.5526932 & 0.926807279577488\\
\hline
Random Forest (mtry = 5) & 0.9053398 & 0.9424460 & 0.5725806 & 0.9518619 & 0.9424460 & 0.9471306 & 0.693016449692199\\
\hline
Adaptive boosting & 0.9029126 & 0.9438914 & 0.5572519 & 0.9473206 & 0.9438914 & 0.9456029 & 0.744030679180543\\
\hline
\end{tabular}
\end{table}

\hypertarget{discussion}{%
\subsection{Discussion}\label{discussion}}

\begin{itemize}
\item
  Do we accept False Positive or False Negative in the context of the
  problem statement?

  \begin{itemize}
  \item
    False Positive, means the client do NOT SUBSCRIBED to term deposit,
    but the model thinks he/she did.

    \begin{itemize}
    \tightlist
    \item
      Type I error is more harmful because we might lose the customer
      and loss revenue by incorrectly considering the client was already
      subscribed.
    \end{itemize}
  \item
    False Negative, means the client SUBSCRIBED to term deposit, but the
    model thinks otherwise.

    \begin{itemize}
    \tightlist
    \item
      Type II error is less harmful because we didn't lose the customer
      and no loss in revenue by incorrectly considering the client was
      not subscribed. We may be contacting the customer for the same
      campaign but it won't cause to lose a customer.
    \end{itemize}
  \end{itemize}
\item
  Flexibility vs Interpretability - what do we choose?

  \begin{itemize}
  \item
    Smaller model(Logistic Regression) are easily interpretable with
    decent accuracy in prediction.
  \item
    Complex, flexible model (Random Forest, Adaptive Boosting) are less
    interpretable but with high accuracy.

    \begin{itemize}
    \tightlist
    \item
      In this study, we must go with complex and flexible model
      eventhough we lose interpretability in the expense for higher
      prediction since it involves revenue to the bank.
    \end{itemize}
  \end{itemize}
\item
  Speed

  \begin{itemize}
  \tightlist
  \item
    We need to choose the model which performs better and run faster.
    Boosting models run in parallel compared to Logistic and Random
    Forest.
  \end{itemize}
\item
  With the above traits for model evaluation and selection techniques,
  we choose ``Adaptive Boosting'' from our study.
\end{itemize}

\hypertarget{conclusion}{%
\subsection{Conclusion}\label{conclusion}}

\begin{itemize}
\item
  In this study, we have applied regression and advanced machine
  learning techniques on bank marketing data and explored the
  distribution of data, data curation and modeling techniques. The below
  are few key highlights.

  \begin{itemize}
  \tightlist
  \item
    Multiple Classification and Regression Algorithms have been
    evaluated.
  \item
    Garbage in - Garbage out so we analyzed the data and curated data to
    further analysis.
  \item
    Oversampling/undersampling has been implemented for class imbalanced
    data.
  \item
    Cross Validation was used for parameter selection with logistic
    regression.
  \item
    Random Forest used with default and best split and tree depth hyper
    parameters tuned to produce better result.
  \item
    Adaptive Boosting is the best model for balanced sensitivities and
    interpretation of feature importance.
  \end{itemize}
\item
  Our study shows that simple and advanced machine learning techniques
  can add value to further a marketing campaign.
\end{itemize}

\hypertarget{appendix}{%
\subsection{Appendix}\label{appendix}}

\hypertarget{team-members}{%
\subsubsection{Team members}\label{team-members}}

\begin{itemize}
\tightlist
\item
  Bhusan Bathani (bbath2)
\item
  Mathew Leung (wmleung2)
\item
  Vijayakumar Sitha Mohan (VS24)
\end{itemize}

\hypertarget{source-repository}{%
\subsubsection{Source Repository}\label{source-repository}}

\begin{itemize}
\tightlist
\item
  \href{https://github.com/smvijaykumar/stat420-group-project}{Our Data
  Analysis Project Source}
\end{itemize}

\hypertarget{uci-machine-learning-library}{%
\subsubsection{UCI machine Learning
Library:}\label{uci-machine-learning-library}}

\begin{itemize}
\item
  \href{http://archive.ics.uci.edu/ml/datasets/Bank+Marketing}{Bank
  Marketing Dataset Source}
\item
  {[}Moro et al., 2014{]} S. Moro, P. Cortez and P. Rita. A Data-Driven
  Approach to Predict the Success of Bank Telemarketing. Decision
  Support Systems, Elsevier, 62:22-31, June 2014
\end{itemize}

\end{document}
